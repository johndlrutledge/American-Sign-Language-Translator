{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "ASL_Basic_learner",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from __future__ import print_function\r\n",
        "import os\r\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten,SpatialDropout2D\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from random import sample\r\n",
        "import os\r\n",
        "import time\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "for gpu in gpus:\r\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)\r\n",
        "tf.keras.mixed_precision.set_global_policy('float32')#'mixed_float16''float32'\r\n",
        "\r\n",
        "data_path = \"D:/ASL/data/\" #put your image folder here directory... subfolders should be named validation and training\r\n",
        "model_path = \"D:/ASL/\"\r\n",
        "classes = 28\r\n",
        "color_mode=\"rgb\"#can change to 'grayscale' for edge detection\r\n",
        "BATCHES = 80\r\n",
        "IMAGESIZE = 200\r\n",
        "if color_mode=='rgb':\r\n",
        "  depth = 3\r\n",
        "else:\r\n",
        "  depth = 1\r\n",
        "\r\n",
        "\"\"\"Put all of your data into a folder named 'unsorted' under data_path. The data_path and model_path variables may be altered according to setup. The structure is as follows:\r\n",
        "{model_path} ---> /{data_path}, /lite ---> /{data_path}/unsorted/\r\n",
        "\r\n",
        "Combined Datasets:\r\n",
        "https://www.kaggle.com/ammarnassanalhajali/american-sign-language-letters\r\n",
        "https://www.kaggle.com/grassknoted/asl-alphabet\r\n",
        "https://www.kaggle.com/belalelwikel/asl-and-some-words\r\n",
        "https://www.kaggle.com/allexmendes/asl-alphabet-synthetic\r\n",
        "https://github.com/ruslan-kl/asl_recognition\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "  \r\n",
        "def abstract_dataset(threshold=10.1,gamma=2.8,ratio = 1.3,kernel_size = 3,image_size=(IMAGESIZE, IMAGESIZE),sigmaColor=4,sigma=20,sigmaSpace=3,data = data_path):\r\n",
        "      \r\n",
        "      def canny_lines(image_path='',threshold=threshold,gamma=gamma,ratio = ratio, kernel_size = kernel_size,image_size=image_size):\r\n",
        "        def adjust_gamma(image_path, gamma=gamma):\r\n",
        "              invGamma = 1.0 / gamma\r\n",
        "              table = np.array([((i / 255.0) ** invGamma) * 255\r\n",
        "                for i in np.arange(0, 256)]).astype(\"uint8\")\r\n",
        "              return cv2.LUT(image_path, table)\r\n",
        "        detected_edges = cv2.imread(image_path, 1)\r\n",
        "        detected_edges = cv2.resize(detected_edges, image_size, interpolation=cv2.INTER_CUBIC)\r\n",
        "        detected_edges = adjust_gamma(detected_edges, gamma=gamma)\r\n",
        "        detected_edges = cv2.cvtColor(detected_edges, cv2.COLOR_BGR2GRAY)\r\n",
        "        detected_edges = cv2.bilateralFilter(detected_edges,sigma,sigmaColor=sigmaColor,sigmaSpace=sigmaSpace)\r\n",
        "        detected_edges = cv2.Canny(detected_edges, threshold, threshold*ratio, kernel_size,L2gradient=True)\r\n",
        "        #detected_edges = 255 - detected_edges\r\n",
        "        return detected_edges\r\n",
        "\r\n",
        "      #create the proper folder structure to store our canny edge detection dataset\r\n",
        "      names = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"nothing\",\"space\"]\r\n",
        "      if not os.path.exists(f\"{data}canny\"):\r\n",
        "        os.mkdir(f\"{data}canny\")\r\n",
        "      if not os.path.exists(f\"{data}canny/training\"):\r\n",
        "            os.mkdir(f\"{data}canny/training/\")\r\n",
        "      if not os.path.exists(f\"{data}canny/validation\"):\r\n",
        "            os.mkdir(f\"{data}canny/validation/\")\r\n",
        "      for i in names:\r\n",
        "        if not os.path.exists(f\"{data}canny/validation/{i}\"):\r\n",
        "            os.mkdir(f\"{data}canny/validation/{i}\")\r\n",
        "        if not os.path.exists(f\"{data}canny/training/{i}\"):\r\n",
        "              os.mkdir(f\"{data}canny/training/{i}\")\r\n",
        "      for i in names:\r\n",
        "        if len([file for file in os.listdir(f\"{data}canny/training/{i}\") if os.path.exists(os.path.join(f\"{data}canny/training/{i}\", file))]) !=0:\r\n",
        "              names.remove(i)\r\n",
        "              print(f\"removing {i}\")\r\n",
        "\r\n",
        "      train_or_val = \"training\"\r\n",
        "      for i in names:     \r\n",
        "        image_path = data+f\"{train_or_val}/\"          \r\n",
        "        filenames = [file for file in os.listdir(image_path+i+\"/\") if os.path.exists(os.path.join(image_path+i+\"/\", file))]#https://stackoverflow.com/questions/3207219/how-do-i-list-all-files-of-a-directory\r\n",
        "        c = 0\r\n",
        "        for file in filenames:\r\n",
        "            c+=1\r\n",
        "            #uncomment to use canny detection when creating dataset\r\n",
        "            #image = canny_lines(image_path+i+\"/\"+file)\r\n",
        "            image_name = f\"{data}canny/{train_or_val}/{i}/c{file}\".split('.')[0] + \".jpg\" #messy function to put file in correct folder\r\n",
        "            cv2.imwrite(image_name, image,[int(cv2.IMWRITE_JPEG_QUALITY), 90])\r\n",
        "            print(f\"Progress edge detecting on {i}: {round(c/len(filenames)*100,0)}%\",end='\\r                     ')\r\n",
        "      \r\n",
        "      train_or_val = \"validation\"\r\n",
        "      for i in names:     \r\n",
        "        image_path = data+f\"{train_or_val}/\"          \r\n",
        "        filenames = [file for file in os.listdir(image_path+i+\"/\") if os.path.isfile(os.path.join(image_path+i+\"/\", file))]\r\n",
        "        c = 0\r\n",
        "        for file in filenames:\r\n",
        "            c+=1\r\n",
        "            image = canny_lines(image_path+i+\"/\"+file)\r\n",
        "            image_name = f\"{data}canny/{train_or_val}/{i}/c{file}\".split('.')[0] + \".jpg\"\r\n",
        "            cv2.imwrite(image_name, image,[int(cv2.IMWRITE_JPEG_QUALITY), 90])\r\n",
        "            print(f\"Progress edge detecting on {i}: {round(c/len(filenames)*100,0)}%\",end='\\r                     ')\r\n",
        "\r\n",
        "def mse(A, B):\r\n",
        "      #https://towardsdatascience.com/image-classification-using-ssim-34e549ec6e12. \r\n",
        "      #Detects how similar two images are\r\n",
        "        A = A.resize((200,200), resample=Image.LANCZOS) \r\n",
        "        B = B.resize((200,200), resample=Image.LANCZOS) \r\n",
        "        A = np.array(A)\r\n",
        "        A = A.astype(np.float32)\r\n",
        "        B = np.array(B)\r\n",
        "        B = B.astype(np.float32)\r\n",
        "        mse_err = np.sum((A - B)**2)\r\n",
        "        mse_err /= float(A.shape[0] * A.shape[1])# return the MSE, the lower the error, the more \"similar\"\r\n",
        "        return mse_err \r\n",
        "\r\n",
        "def sort_and_avoid_duplicates(folder=f\"{data_path}/unsorted/\",percent_val=.08,remove_duplicates_threshold=0,display_dups=False):\r\n",
        "    names = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",\"nothing\",\"space\"]\r\n",
        "    if not os.path.exists(f\"{data_path}training\"):\r\n",
        "          os.mkdir(f\"{data_path}training/\")\r\n",
        "    if not os.path.exists(f\"{data_path}validation\"):\r\n",
        "          os.mkdir(f\"{data_path}validation/\")\r\n",
        "    for i in names:\r\n",
        "      if not os.path.exists(f\"{data_path}validation/{i}\"):\r\n",
        "          os.mkdir(f\"{data_path}validation/{i}\")\r\n",
        "      if not os.path.exists(f\"{data_path}training/{i}\"):\r\n",
        "            os.mkdir(f\"{data_path}training/{i}\")\r\n",
        "    for folders in names:\r\n",
        "          asl_images = [file for file in os.listdir(folder+folders+\"/\") if os.path.exists(os.path.join(folder+folders+\"/\"))]\r\n",
        "          validation = sample(asl_images,round(float(len(asl_images))*percent_val))\r\n",
        "          training = [i for i in asl_images if i not in validation]\r\n",
        "          asl_images = None\r\n",
        "          for v in validation:\r\n",
        "                nospam = True\r\n",
        "                if remove_duplicates_threshold != 0:\r\n",
        "                #The time cost is very exponential for this function, so it is not practical for our timeframe to scan for and remove duplicate images\r\n",
        "                      for t in training:\r\n",
        "                            p_similarity = mse(Image.open(folder+folders+\"/\"+v),Image.open(folder+folders+\"/\"+t))\r\n",
        "                            if p_similarity<remove_duplicates_threshold:\r\n",
        "                                  if nospam:\r\n",
        "                                    if display_dups:\r\n",
        "                                      os.system(folder+folders+'/'+v)\r\n",
        "                                      os.system(folder+folders+'/'+t)\r\n",
        "                                    nospam=False\r\n",
        "                                    break\r\n",
        "                                  print(f\"{p_similarity}   {folder+folders+'/'+v}    {folder+folders+'/'+t}\")\r\n",
        "                            print(v,\"---> \",t,end='\\r                  ')\r\n",
        "                if nospam:\r\n",
        "                      try:\r\n",
        "                        image = cv2.imread(folder+folders+\"/\"+v, 1)\r\n",
        "                        cv2.imwrite(data_path+\"validation/\"+folders+\"/\"+v.split(\".\")[0]+\".jpg\", image,[int(cv2.IMWRITE_JPEG_QUALITY), 90])\r\n",
        "                        print(\"collected \",data_path+\"validation/\"+folders+\"/\"+v.split(\".\")[0]+\".jpg\")\r\n",
        "                      except Exception as error:\r\n",
        "                        print(error)\r\n",
        "                else:\r\n",
        "                      try:\r\n",
        "                        image = cv2.imread(folder+folders+\"/\"+v, 1)\r\n",
        "                        cv2.imwrite(data_path+\"training/\"+folders+\"/\"+v.split(\".\")[0]+\".jpg\", image,[int(cv2.IMWRITE_JPEG_QUALITY), 90])\r\n",
        "                      except Exception as error:\r\n",
        "                        print(error)\r\n",
        "          for t in training:\r\n",
        "                if t not in validation:\r\n",
        "                      try:\r\n",
        "                        image = cv2.imread(folder+folders+\"/\"+t, 1)\r\n",
        "                        cv2.imwrite(data_path+\"training/\"+folders+\"/\"+t.split(\".\")[0]+\".jpg\", image,[int(cv2.IMWRITE_JPEG_QUALITY), 90])\r\n",
        "                      except Exception as error:\r\n",
        "                        print(error)\r\n",
        "\r\n",
        "if not os.path.exists(f\"{data_path}training\") or not os.path.exists(f\"{data_path}validation\"):sort_and_avoid_duplicates(percent_val=.08,remove_duplicates_threshold=0) #sort images into \r\n",
        "\r\n",
        "if not os.path.exists(data_path+\"canny/validation\") or not os.path.exists(data_path+\"canny/training\"): abstract_dataset()\r\n",
        "    \r\n",
        "\r\n",
        "train_data = tf.keras.utils.image_dataset_from_directory(\r\n",
        "    data_path + \"canny/\" + \"training\", labels='inferred', label_mode='categorical',\r\n",
        "    class_names=None, color_mode=color_mode, batch_size=BATCHES, image_size=(IMAGESIZE,\r\n",
        "    IMAGESIZE), shuffle=True, seed=34667,\r\n",
        "    interpolation='lanczos5', follow_links=False,\r\n",
        "    crop_to_aspect_ratio=True\r\n",
        ")\r\n",
        "\r\n",
        "test_data = tf.keras.utils.image_dataset_from_directory(\r\n",
        "    data_path + \"canny/\" + \"validation\", labels='inferred', label_mode='categorical',\r\n",
        "    class_names=None, color_mode=color_mode, batch_size=BATCHES, image_size=(IMAGESIZE,\r\n",
        "    IMAGESIZE), shuffle=True, seed=34667,\r\n",
        "    interpolation='lanczos5', follow_links=False,\r\n",
        "    crop_to_aspect_ratio=True)\r\n",
        "\r\n",
        "\r\n",
        "def define_model(pooling = (2,2),kernel_size = (3,3),filters=32,activation='swish',noise=.9,dropout=.2,rotation=.1,zoom=(-.01,.05)):\r\n",
        "      \r\n",
        "  #https://www.tensorflow.org/tutorials/images/data_augmentation\r\n",
        "  train_mod = Sequential([\r\n",
        "    layers.RandomFlip(mode=\"horizontal\",input_shape=(IMAGESIZE, IMAGESIZE,depth)),\r\n",
        "    layers.RandomRotation(rotation,fill_mode='nearest'),\r\n",
        "    layers.GaussianNoise(noise),\r\n",
        "    layers.RandomZoom(height_factor=zoom,fill_mode='nearest'),\r\n",
        "    layers.experimental.preprocessing.Resizing(height=IMAGESIZE, width=IMAGESIZE,crop_to_aspect_ratio=True),\r\n",
        "    layers.experimental.preprocessing.Rescaling(scale=1./255),\r\n",
        "    \r\n",
        "    Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, input_shape=(IMAGESIZE, IMAGESIZE,depth)),\r\n",
        "    Conv2D(filters=filters, kernel_size=kernel_size, activation=activation),\r\n",
        "    MaxPooling2D(pooling),\r\n",
        "    SpatialDropout2D(dropout),\r\n",
        "    Conv2D(filters=filters*2, kernel_size=kernel_size, activation=activation),\r\n",
        "    Conv2D(filters=filters*2, kernel_size=kernel_size, activation=activation),\r\n",
        "    MaxPooling2D(pooling),\r\n",
        "    \r\n",
        "    Flatten(),\r\n",
        "    Dense(250, activation=activation),\r\n",
        "    Dense(128, activation=activation),\r\n",
        "    Dense(64, activation=activation),\r\n",
        "    Dense(classes, activation='softmax')\r\n",
        "    ])\r\n",
        "  return train_mod\r\n",
        "\r\n",
        "model = define_model()\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, amsgrad=False), loss='categorical_crossentropy', metrics='accuracy')\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#model training\r\n",
        "model.fit(train_data,shuffle=True,use_multiprocessing=True,epochs=200,validation_data = test_data,callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10,mode='auto',restore_best_weights=True)])\r\n",
        "\r\n",
        "\r\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)#https://medium.com/analytics-vidhya/optimization-techniques-tflite-5f6d9ae676d5\r\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
        "\r\n",
        "tflite_model = converter.convert()\r\n",
        "with open(model_path+\"/lite/\"+f'model{time.time()}.tflite', 'wb') as f:\r\n",
        "  f.write(tflite_model)"
      ],
      "outputs": [],
      "metadata": {
        "id": "K_n7AmobE-MY"
      }
    }
  ]
}